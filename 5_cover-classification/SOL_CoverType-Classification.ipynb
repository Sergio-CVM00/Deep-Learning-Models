{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Cover Type Classification\n",
    "   \n",
    "   ### Objective: Build a deep learning model to predict the forest cover type from different cartographic variables.\n",
    "   ### Given: \n",
    "       1. Cover Types: ['Spruce/Fir', 'Lodgepole Pine','Ponderosa Pine', 'Cottonwood/Willow','Aspen', 'Douglas-fir', 'Krummholz']\n",
    "       2. A csv file ('cover_data.csv') that contains 581012 observations. Each observation has 55 columns (54 features and the last one being the class).\n",
    "   ### Assumption(s):\n",
    "       1. There are no separate test dataset. So, one must hold-out a small percentage of given input as test data.\n",
    "       2. There is no information about the use of predictions. Hence, we do not know how what to focus on (precision or recall). Generally, it's a good idea to have both scores 'high'.\n",
    "   ### Expected output: \n",
    "       1. A good model.\n",
    "       2. Model performance over epochs (accuracy, loss plots)\n",
    "       3. Some classification metrics (heatmap of confusion-matrix, classification-report etc).\n",
    "       4. Conclusions, thoughts and ways to improve classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 11:39:30.646074: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-19 11:39:30.722214: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-19 11:39:30.758327: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-19 11:39:30.820680: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-19 11:39:30.836742: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-19 11:39:30.927257: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-19 11:39:32.135413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sweetviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msweetviz\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msv\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sweetviz'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sweetviz as sv\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable those annoying warnings\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# Turn off GPU usage for tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(raw_df):\n",
    "    \"\"\"\n",
    "    Prepare data that can be readily consumed by ML/DL algorithms.\n",
    "    - separate features from class variables\n",
    "    - split into training and testing dataset\n",
    "    - scale numerical data\n",
    "    \n",
    "    param: a dataframe of input data\n",
    "    output: X_train_normalized, X_test_normalized, y_train, y_test\n",
    "    \"\"\"\n",
    "    raw_data = raw_df.values\n",
    "    X, y = raw_data[:, :-1], raw_data[:, -1]\n",
    "\n",
    "    # Split into train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "    # normalize data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_normalized, X_test_normalized, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_features):\n",
    "    \"\"\"\n",
    "    Build the model architecture (and compile it).\n",
    "    input: number of features\n",
    "    output: Keras model object.\n",
    "    \"\"\"\n",
    "    classifier = keras.Sequential()\n",
    "    classifier.add(layers.Dense(64, input_dim=num_features, activation='relu'))\n",
    "    #classifier.add(layers.Dropout(0.3))\n",
    "    classifier.add(layers.Dense(32, activation='relu'))\n",
    "    #classifier.add(layers.Dropout(0.3))\n",
    "    classifier.add(layers.Dense(8, activation='softmax'))\n",
    "    classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(class_names, y_pred, y_test):\n",
    "    \"\"\"\n",
    "    Function to compute a Confusion Matrix and plot a heatmap based on the matrix.\n",
    "    input: class names, y-predicted, y-test (ground-truth)\n",
    "    output: a PNG file of the heatmap.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    heatmap = sns.heatmap(cm, fmt='g', cmap='Blues', annot=True, ax=ax)\n",
    "    ax.set_xlabel('Predicted class')\n",
    "    ax.set_ylabel('True class')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(class_names)\n",
    "    ax.yaxis.set_ticklabels(class_names)\n",
    "    # Save the heatmap to file\n",
    "    heatmapfig = heatmap.get_figure()\n",
    "    heatmapfig.savefig(f'confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, param):\n",
    "    \"\"\"\n",
    "    Shows how the model performs (in terms of accuracy and loss) over several epochs.\n",
    "    \"\"\"\n",
    "    if param == 'acc':\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.show()\n",
    "    elif param == 'loss':\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'val'], loc='upper right')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main function below drives the entire code. It prepares the dataset, builds a model with appropriate parameters, evaluates the model and predicts on the test data. Finally, plots some performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    infile = 'cover_data.csv'\n",
    "    raw_df = pd.read_csv(infile)\n",
    "\n",
    "    # EDA\n",
    "    # Uncomment the below two lines to run EDA. Takes > 10 min to run.\n",
    "    #my_report = sv.analyze(raw_df)\n",
    "    #my_report.show_html()\n",
    "\n",
    "    cols = raw_df.columns.tolist()\n",
    "    features, label = cols[:-1], cols[-1]\n",
    "    X_train, X_test, y_train, y_test = prep_data(raw_df)\n",
    "\n",
    "    # Build a DL model\n",
    "    num_features = len(features)\n",
    "    model = build_model(num_features)\n",
    "\n",
    "    print(\"Summary report of Keras classifier:\")\n",
    "    model.summary()\n",
    "\n",
    "    num_epochs = 100\n",
    "    batch_size = 1024\n",
    "    earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=3)\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=num_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[earlystop_callback],\n",
    "                        validation_split=0.1,\n",
    "                        verbose=1)\n",
    "\n",
    "    plot_history(history, 'acc')\n",
    "    plot_history(history, 'loss')\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f'Test loss: {score[0]}')\n",
    "    print(f'Test accuracy: {score[1]}')\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Convert the pred to discrete values\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "    class_names = ['Spruce/Fir', 'Lodgepole Pine',\n",
    "                   'Ponderosa Pine', 'Cottonwood/Willow',\n",
    "                   'Aspen', 'Douglas-fir', 'Krummholz']\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "    plot_heatmap(class_names, y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions: \n",
    "The numbers along the diagonal of the heatmap show how many were correctly classified. All other numbers on either sides of the diagonal show mis-classifications. We see that Lodgepole Pine, Cottonwood Willow, Aspen, and Douglas-Fir suffer from a high percentage of mis-classifications. To investigate the possible causes, one can explore the following:\n",
    "\n",
    "1. Check the proportion of observations for each cover-type. Imbalances in the dataset will affect classification.\n",
    "2. How each wilderness area is distributed.\n",
    "3. Find the similarties among different cover-types (correlation, scatter-plots, etc.) These similarities might be one of the reasons the model might be tripping-up. There are ways to address it - one of it is to carefully remove all of the collinear variables, leaving only one.\n",
    "4. Remove noise, inconsistent data and errors in training data - this should be done carefully with domain experts.\n",
    "5. Try to use some other performance metric other than 'accuracy'. It fails to be a reliable metric when data in imbalanced. That is why we have other metrics such as Precision/Recall, F1-score etc.\n",
    "6. Try resampling the data (undersample or oversample appropriately or stratified). Downsampling could be done with thresholding.\n",
    "\n",
    "The most important thing to understand here is that in deep-learning, the gradient(s) of the majority class(es) dominate(s) and will influence the weight-updates. There are also some advanced techniques that will ameliorate this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
